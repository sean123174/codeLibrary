{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the decimal returns into percentage returns\n",
    "percent_return = StockPrices['Returns']*100\n",
    "\n",
    "# Drop the missing values\n",
    "returns_plot = percent_return.dropna()\n",
    "\n",
    "# Plot the returns histogram\n",
    "plt.hist(returns_plot, bins=75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import skew from scipy.stats\n",
    "from scipy.stats import skew\n",
    "\n",
    "# Drop the missing values\n",
    "clean_returns = StockPrices['Returns'].dropna()\n",
    "\n",
    "# Calculate the third moment (skewness) of the returns distribution\n",
    "returns_skewness = skew(clean_returns)\n",
    "print(returns_skewness)\n",
    "\n",
    "# Import kurtosis from scipy.stats\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "# Calculate the excess kurtosis of the returns distribution\n",
    "excess_kurtosis = kurtosis(clean_returns)\n",
    "print(excess_kurtosis)\n",
    "\n",
    "# Derive the true fourth moment of the returns distribution\n",
    "fourth_moment = excess_kurtosis+3\n",
    "print(fourth_moment)\n",
    "\n",
    "# Import shapiro from scipy.stats\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# Run the Shapiro-Wilk test on the stock returns\n",
    "shapiro_results = shapiro(clean_returns)\n",
    "print(\"Shapiro results:\", shapiro_results)\n",
    "\n",
    "# Extract the p-value from the shapiro_results\n",
    "p_value = shapiro_results[1]\n",
    "print(\"P-value: \", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish defining the portfolio weights as a numpy array\n",
    "portfolio_weights = np.array([0.12, 0.15, 0.08, 0.05, 0.09, 0.10, 0.11, 0.14, 0.16])\n",
    "\n",
    "# Calculate the weighted stock returns\n",
    "WeightedReturns = StockReturns.mul(portfolio_weights, axis=1)\n",
    "\n",
    "# Calculate the portfolio returns\n",
    "StockReturns['Portfolio'] = WeightedReturns.sum(axis=1)\n",
    "\n",
    "# Plot the cumulative portfolio returns over time\n",
    "CumulativeReturns = ((1+StockReturns[\"Portfolio\"]).cumprod()-1)\n",
    "CumulativeReturns.plot()\n",
    "plt.show()\n",
    "\n",
    "# How many stocks are in your portfolio?\n",
    "numstocks = 9\n",
    "\n",
    "# Create an array of equal weights across all assets\n",
    "portfolio_weights_ew = np.repeat(1/numstocks, numstocks)\n",
    "\n",
    "# Calculate the equally-weighted portfolio returns\n",
    "StockReturns['Portfolio_EW'] = StockReturns.iloc[:, 0:numstocks].mul(portfolio_weights_ew, axis=1).sum(axis=1)\n",
    "cumulative_returns_plot(['Portfolio', 'Portfolio_EW'])\n",
    "\n",
    "# Create an array of market capitalizations (in billions)\n",
    "market_capitalizations = np.array([601.51, 469.25, 349.5, 310.48, 299.77, 356.94, 268.88, 331.57, 246.09])\n",
    "\n",
    "# Calculate the market cap weights\n",
    "mcap_weights = market_capitalizations / sum(market_capitalizations)\n",
    "\n",
    "# Calculate the market cap weighted portfolio returns\n",
    "StockReturns['Portfolio_MCap'] = StockReturns.iloc[:, 0:9].mul(mcap_weights, axis=1).sum(axis=1)\n",
    "cumulative_returns_plot(['Portfolio', 'Portfolio_EW', 'Portfolio_MCap'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capital Asset Pricing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate excess portfolio returns\n",
    "FamaFrenchData['Portfolio_Excess'] = FamaFrenchData['Portfolio'] - FamaFrenchData['RF']\n",
    "\n",
    "# Plot returns vs excess returns\n",
    "CumulativeReturns = ((1+FamaFrenchData[['Portfolio','Portfolio_Excess']]).cumprod()-1)\n",
    "CumulativeReturns.plot()\n",
    "plt.show()\n",
    "\n",
    "# Calculate the co-variance matrix between Portfolio_Excess and Market_Excess\n",
    "covariance_matrix = FamaFrenchData[['Portfolio_Excess', 'Market_Excess']].cov()\n",
    "\n",
    "# Extract the co-variance co-efficient\n",
    "covariance_coefficient = covariance_matrix.iloc[0, 1]\n",
    "print(covariance_coefficient)\n",
    "\n",
    "# Calculate the benchmark variance\n",
    "benchmark_variance = FamaFrenchData['Market_Excess'].var()\n",
    "print(benchmark_variance)\n",
    "\n",
    "# Calculating the portfolio market beta\n",
    "portfolio_beta = covariance_coefficient / benchmark_variance\n",
    "print(portfolio_beta)\n",
    "\n",
    "# Import statsmodels.formula.api\n",
    "import statsmodels.formula.api as smf \n",
    "\n",
    "# Define the regression formula\n",
    "CAPM_model = smf.ols(formula='Portfolio_Excess ~ Market_Excess', data=FamaFrenchData)\n",
    "\n",
    "# Print adjusted r-squared of the fitted regression\n",
    "CAPM_fit = CAPM_model.fit()\n",
    "print(CAPM_fit.rsquared_adj)\n",
    "\n",
    "# Extract the beta\n",
    "regression_beta = CAPM_fit.params['Market_Excess']\n",
    "print(regression_beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fama-French 3 factor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statsmodels.formula.api\n",
    "import statsmodels.formula.api as smf \n",
    "\n",
    "# Define the regression formula\n",
    "FamaFrench_model = smf.ols(formula='Portfolio_Excess ~ Market_Excess + SMB + HML', data=FamaFrenchData)\n",
    "\n",
    "# Fit the regression\n",
    "FamaFrench_fit = FamaFrench_model.fit()\n",
    "\n",
    "# Extract the adjusted r-squared\n",
    "regression_adj_rsq = FamaFrench_fit.rsquared_adj\n",
    "print(regression_adj_rsq)\n",
    "\n",
    "# Extract the p-value of the SMB factor\n",
    "smb_pval = FamaFrench_fit.pvalues['SMB']\n",
    "\n",
    "# If the p-value is significant, print significant\n",
    "if smb_pval < 0.05:\n",
    "    significant_msg = 'significant'\n",
    "else:\n",
    "    significant_msg = 'not significant'\n",
    "\n",
    "# Print the SMB coefficient\n",
    "smb_coeff = FamaFrench_fit.params['SMB']\n",
    "print(\"The SMB coefficient is \", smb_coeff, \" and is \", significant_msg)\n",
    "\n",
    "# Calculate your portfolio alpha\n",
    "portfolio_alpha = FamaFrench_fit.params['Intercept']\n",
    "print(portfolio_alpha)\n",
    "\n",
    "# Annualize your portfolio alpha\n",
    "portfolio_alpha_annualized = ((1 + portfolio_alpha)**252)-1\n",
    "print(portfolio_alpha_annualized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statsmodels.formula.api\n",
    "import statsmodels.formula.api as smf \n",
    "\n",
    "# Define the regression formula\n",
    "FamaFrench5_model = smf.ols(formula='Portfolio_Excess ~ Market_Excess + SMB + HML + RMW + CMA ', data=FamaFrenchData)\n",
    "\n",
    "# Fit the regression\n",
    "FamaFrench5_fit = FamaFrench5_model.fit()\n",
    "\n",
    "# Extract the adjusted r-squared\n",
    "regression_adj_rsq = FamaFrench5_fit.rsquared_adj\n",
    "print(regression_adj_rsq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating Tail Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historical Draw Down\n",
    "# Calculate the running maximum\n",
    "running_max = np.maximum.accumulate(cum_rets)\n",
    "\n",
    "# Ensure the value never drops below 1\n",
    "running_max[running_max < 1] = 1\n",
    "\n",
    "# Calculate the percentage drawdown\n",
    "drawdown = (cum_rets)/running_max - 1\n",
    "\n",
    "# Plot the results\n",
    "drawdown.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historical Values at Risk\n",
    "\n",
    "# Calculate historical VaR(95)\n",
    "var_95 = np.percentile(StockReturns_perc, 5)\n",
    "print(var_95)\n",
    "\n",
    "# Sort the returns for plotting\n",
    "sorted_rets = StockReturns_perc.sort_values()\n",
    "\n",
    "# Plot the probability of each sorted return quantile\n",
    "plt.hist(sorted_rets, density=True, stacked=True)\n",
    "\n",
    "# Denote the VaR 95 quantile\n",
    "plt.axvline(x=var_95, color='r', linestyle='-', label=\"VaR 95: {0:.2f}%\".format(var_95))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Conditional Values at Risk\n",
    "\n",
    "# Historical CVaR 95\n",
    "cvar_95 = StockReturns_perc[StockReturns_perc<=var_95].mean()\n",
    "print(cvar_95)\n",
    "\n",
    "# Sort the returns for plotting\n",
    "sorted_rets = sorted(StockReturns_perc)\n",
    "\n",
    "# Plot the probability of each return quantile\n",
    "plt.hist(sorted_rets, density=True, stacked=True)\n",
    "\n",
    "# Denote the VaR 95 and CVaR 95 quantiles\n",
    "plt.axvline(x=var_95, color=\"r\", linestyle=\"-\", label='VaR 95: {0:.2f}%'.format(var_95))\n",
    "plt.axvline(x=cvar_95, color='b', linestyle='-', label='CVaR 95: {0:.2f}%'.format(cvar_95))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import norm from scipy.stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Estimate the average daily return\n",
    "mu = np.mean(StockReturns)\n",
    "\n",
    "# Estimate the daily volatility\n",
    "vol = np.std(StockReturns)\n",
    "\n",
    "# Set the VaR confidence level\n",
    "confidence_level = 0.05\n",
    "\n",
    "# Calculate Parametric VaR\n",
    "var_95 = norm.ppf(confidence_level, mu, vol)\n",
    "print('Mean: ', str(mu), '\\nVolatility: ', str(vol), '\\nVaR(95): ', str(var_95))\n",
    "\n",
    "# Aggregate forecasted VaR\n",
    "forecasted_values = np.empty([100, 2])\n",
    "\n",
    "# Loop through each forecast period\n",
    "for i in range(100):\n",
    "    # Save the time horizon i\n",
    "    forecasted_values[i, 0] = i\n",
    "    # Save the forecasted VaR 95\n",
    "    forecasted_values[i, 1] = var_95*np.sqrt(i+1)\n",
    "    \n",
    "# Plot the results\n",
    "plot_var_scale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the simulation parameters\n",
    "mu = np.mean(StockReturns)\n",
    "vol = np.std(StockReturns)\n",
    "T = 252\n",
    "S0 = 10\n",
    "\n",
    "# Add one to the random returns\n",
    "rand_rets = np.random.normal(mu, vol, T) + 1\n",
    "\n",
    "# Forecasted random walk\n",
    "forecasted_values = S0 * (rand_rets.cumprod())\n",
    "\n",
    "# Plot the random walk\n",
    "plt.plot(range(0, T), forecasted_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through 100 simulations\n",
    "for i in range(100):\n",
    "\n",
    "    # Generate the random returns\n",
    "    rand_rets = np.random.normal(mu, vol, T) + 1\n",
    "    \n",
    "    # Create the Monte carlo path\n",
    "    forecasted_values = S0*(rand_rets).cumprod()\n",
    "    \n",
    "    # Plot the Monte Carlo path\n",
    "    plt.plot(range(T), forecasted_values)\n",
    "\n",
    "# Show the simulations\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the returns\n",
    "sim_returns = []\n",
    "\n",
    "# Loop through 100 simulations\n",
    "for i in range(100):\n",
    "\n",
    "    # Generate the Random Walk\n",
    "    rand_rets = np.random.normal(mu, vol, T)\n",
    "    \n",
    "    # Save the results\n",
    "    sim_returns.append(rand_rets)\n",
    "\n",
    "# Calculate the VaR(99)\n",
    "var_99 = np.percentile(sim_returns, 1)\n",
    "print(\"Parametric VaR(99): \", round(100*var_99, 2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Risk Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select portfolio asset prices for the middle of the crisis, 2008-2009\n",
    "asset_prices = portfolio.loc['2008-01-01':'2009-12-31']\n",
    "\n",
    "# Plot portfolio's asset prices during this time\n",
    "asset_prices.plot().set_ylabel(\"Closing Prices, USD\")\n",
    "plt.show()\n",
    "\n",
    "# Compute the portfolio's daily returns\n",
    "asset_returns = asset_prices.pct_change()\n",
    "portfolio_returns = asset_returns.dot(weights)\n",
    "\n",
    "# Plot portfolio returns\n",
    "portfolio_returns.plot().set_ylabel(\"Daily Return, %\")\n",
    "plt.show()\n",
    "\n",
    "# Generate the covariance matrix from portfolio asset's returns\n",
    "covariance = asset_returns.cov()\n",
    "\n",
    "# Annualize the covariance using 252 trading days per year\n",
    "covariance = covariance * 252\n",
    "\n",
    "# Display the covariance matrix\n",
    "print(covariance)\n",
    "\n",
    "# Compute and display portfolio volatility for 2008 - 2009\n",
    "portfolio_variance = np.transpose(weights) @ covariance @ weights\n",
    "portfolio_volatility = np.sqrt(portfolio_variance)\n",
    "print(portfolio_volatility)\n",
    "\n",
    "# Calculate the 30-day rolling window of portfolio returns\n",
    "returns_windowed = portfolio_returns.rolling(30)\n",
    "\n",
    "# Compute the annualized volatility series\n",
    "volatility_series = returns_windowed.std()*np.sqrt(252)\n",
    "\n",
    "# Plot the portfolio volatility\n",
    "volatility_series.plot().set_ylabel(\"Annualized Volatility, 30-day Window\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert daily returns to quarterly average returns\n",
    "returns_q = returns.resample('Q').mean()\n",
    "\n",
    "# Examine the beginning of the quarterly series\n",
    "print(returns_q.head())\n",
    "\n",
    "# Now convert daily returns to weekly minimum returns\n",
    "returns_w = returns.resample('W').min()\n",
    "\n",
    "# Examine the beginning of the weekly series\n",
    "print(returns_w.head())\n",
    "\n",
    "# Transform the daily portfolio_returns into quarterly average returns\n",
    "portfolio_q_average = portfolio_returns.resample('Q').mean().dropna()\n",
    "\n",
    "# Create a scatterplot between delinquency and quarterly average returns\n",
    "plot_average.scatter(mort_del, portfolio_q_average)\n",
    "\n",
    "# Transform daily portfolio_returns returns into quarterly minimum returns\n",
    "portfolio_q_min = portfolio_returns.resample('Q').min().dropna()\n",
    "\n",
    "# Create a scatterplot between delinquency and quarterly minimum returns\n",
    "plot_min.scatter(mort_del, portfolio_q_min)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a constant to the regression\n",
    "mort_del = sm.add_constant(mort_del)\n",
    "\n",
    "# Create the regression factor model and fit it to the data\n",
    "results = sm.OLS(port_q_mean, mort_del).fit()\n",
    "\n",
    "# Print a summary of the results\n",
    "print(results.summary())\n",
    "\n",
    "# Add a constant to the regression\n",
    "mort_del = sm.add_constant(mort_del)\n",
    "\n",
    "# Create the regression factor model and fit it to the data\n",
    "results = sm.OLS(port_q_min, mort_del).fit()\n",
    "\n",
    "# Print a summary of the results\n",
    "print(results.summary())\n",
    "\n",
    "# Add a constant to the regression\n",
    "mort_del = sm.add_constant(mort_del)\n",
    "\n",
    "# Create the regression factor model and fit it to the data\n",
    "results = sm.OLS(vol_q_mean, mort_del).fit()\n",
    "\n",
    "# Print a summary of the results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the investment portfolio price data into the price variable.\n",
    "prices = pd.read_csv(\"portfolio.csv\")\n",
    "\n",
    "# Convert the 'Date' column to a datetime index\n",
    "prices['Date'] = pd.to_datetime(prices['Date'], format='%d/%m/%Y')\n",
    "prices.set_index(['Date'], inplace = True)\n",
    "\n",
    "# Import the mean_historical_return method\n",
    "from pypfopt.expected_returns import mean_historical_return\n",
    "\n",
    "# Compute the annualized average historical return\n",
    "mean_returns = mean_historical_return(prices, frequency = 252)\n",
    "\n",
    "# Plot the annualized average historical return\n",
    "plt.plot(mean_returns, linestyle = 'None', marker = 'o')\n",
    "plt.show()\n",
    "\n",
    "# Import the CovarianceShrinkage object\n",
    "from pypfopt.risk_models import CovarianceShrinkage\n",
    "\n",
    "# Create the CovarianceShrinkage instance variable\n",
    "cs = CovarianceShrinkage(prices)\n",
    "\n",
    "# Compute the sample covariance matrix of returns\n",
    "sample_cov = prices.pct_change().cov() * 252\n",
    "\n",
    "# Compute the efficient covariance matrix of returns\n",
    "e_cov = cs.ledoit_wolf()\n",
    "\n",
    "# Display both the sample covariance_matrix and the efficient e_cov estimate\n",
    "print(\"Sample Covariance Matrix\\n\", sample_cov, \"\\n\")\n",
    "print(\"Efficient Covariance Matrix\\n\", e_cov, \"\\n\")\n",
    "\n",
    "# Create a dictionary of time periods (or 'epochs')\n",
    "epochs = { 'before' : {'start': '1-1-2005', 'end': '31-12-2006'},\n",
    "           'during' : {'start': '1-1-2007', 'end': '31-12-2008'},\n",
    "           'after'  : {'start': '1-1-2009', 'end': '31-12-2010'}\n",
    "         }\n",
    "\n",
    "# Compute the efficient covariance for each epoch\n",
    "e_cov = {}\n",
    "for x in epochs.keys():\n",
    "  sub_price = prices.loc[epochs[x]['start']:epochs[x]['end']]\n",
    "  e_cov[x] = CovarianceShrinkage(sub_price).ledoit_wolf()\n",
    "\n",
    "# Display the efficient covariance matrices for all epochs\n",
    "print(\"Efficient Covariance Matrices\\n\", e_cov)\n",
    "\n",
    "# Initialize the Crtical Line Algorithm object\n",
    "efficient_portfolio_during = CLA(returns_during, ecov_during)\n",
    "\n",
    "# Find the minimum volatility portfolio weights and display them\n",
    "print(efficient_portfolio_during.min_volatility())\n",
    "\n",
    "# Compute the efficient frontier\n",
    "(ret, vol, weights) = efficient_portfolio_during.efficient_frontier()\n",
    "\n",
    "# Add the frontier to the plot showing the 'before' and 'after' frontiers\n",
    "plt.scatter(vol, ret, s = 4, c = 'g', marker = '.', label = 'During')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
